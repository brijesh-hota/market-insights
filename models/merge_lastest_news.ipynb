{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load data into a DataFrame\n",
    "df = pd.read_csv('../stocks_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest headlines for each stock group on each date saved to 'latest_headlines.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>datetime</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>datetime_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1672549729</td>\n",
       "      <td>Luminar, Aurora, MicroVision: Who Wins In The ...</td>\n",
       "      <td>118066708</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>Click here for an in-depth analysis across the...</td>\n",
       "      <td>https://finnhub.io/api/news?id=07ee79fe35f070a...</td>\n",
       "      <td>2023-01-01 01:08:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1672634160</td>\n",
       "      <td>These 10 Mega-Cap Stocks Flopped in 2022</td>\n",
       "      <td>118089053</td>\n",
       "      <td>TipRanks</td>\n",
       "      <td>Looking for stock market analysis and research...</td>\n",
       "      <td>https://finnhub.io/api/news?id=ad0ee1a31acd47c...</td>\n",
       "      <td>2023-01-02 00:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1672719360</td>\n",
       "      <td>Apple downgraded to Neutral from Outperform at...</td>\n",
       "      <td>118097919</td>\n",
       "      <td>Thefly.com</td>\n",
       "      <td>Looking for stock market analysis and research...</td>\n",
       "      <td>https://finnhub.io/api/news?id=c94bafbd39d76d2...</td>\n",
       "      <td>2023-01-03 00:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1672806957</td>\n",
       "      <td>China's 2025 Strategy Emerges As Top 2023 Inve...</td>\n",
       "      <td>118110299</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>The most important investment story of 2023 wi...</td>\n",
       "      <td>https://finnhub.io/api/news?id=f6acfb521bd94a6...</td>\n",
       "      <td>2023-01-04 00:35:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1672892100</td>\n",
       "      <td>BMW Takes Cues From Apple With Radical Interio...</td>\n",
       "      <td>118133082</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>(Bloomberg) -- BMW AG’s latest prototype could...</td>\n",
       "      <td>https://finnhub.io/api/news?id=60dae185ca4d6d6...</td>\n",
       "      <td>2023-01-05 00:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  related    datetime                                           headline  \\\n",
       "0    AAPL  1672549729  Luminar, Aurora, MicroVision: Who Wins In The ...   \n",
       "1    AAPL  1672634160           These 10 Mega-Cap Stocks Flopped in 2022   \n",
       "2    AAPL  1672719360  Apple downgraded to Neutral from Outperform at...   \n",
       "3    AAPL  1672806957  China's 2025 Strategy Emerges As Top 2023 Inve...   \n",
       "4    AAPL  1672892100  BMW Takes Cues From Apple With Radical Interio...   \n",
       "\n",
       "          id        source                                            summary  \\\n",
       "0  118066708  SeekingAlpha  Click here for an in-depth analysis across the...   \n",
       "1  118089053      TipRanks  Looking for stock market analysis and research...   \n",
       "2  118097919    Thefly.com  Looking for stock market analysis and research...   \n",
       "3  118110299  SeekingAlpha  The most important investment story of 2023 wi...   \n",
       "4  118133082         Yahoo  (Bloomberg) -- BMW AG’s latest prototype could...   \n",
       "\n",
       "                                                 url       datetime_norm  \n",
       "0  https://finnhub.io/api/news?id=07ee79fe35f070a... 2023-01-01 01:08:49  \n",
       "1  https://finnhub.io/api/news?id=ad0ee1a31acd47c... 2023-01-02 00:36:00  \n",
       "2  https://finnhub.io/api/news?id=c94bafbd39d76d2... 2023-01-03 00:16:00  \n",
       "3  https://finnhub.io/api/news?id=f6acfb521bd94a6... 2023-01-04 00:35:57  \n",
       "4  https://finnhub.io/api/news?id=60dae185ca4d6d6... 2023-01-05 00:15:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Convert 'datetime_norm' to datetime format\n",
    "df['datetime_norm'] = pd.to_datetime(df['datetime_norm'])\n",
    "\n",
    "# Step 4: Group by 'related' and 'date', then find the latest headline for each group\n",
    "latest_headlines = df.groupby(['related', df['datetime_norm'].dt.date], as_index=False).last()\n",
    "\n",
    "print(\"Latest headlines for each stock group on each date saved to 'latest_headlines.csv'.\")\n",
    "\n",
    "latest_headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows corresponding to weekends have been dropped, and the filtered DataFrame is saved to 'stocks_news_merge.csv'.\n"
     ]
    }
   ],
   "source": [
    "df = latest_headlines\n",
    "\n",
    "# Step 2: Convert 'datetime_norm' to datetime format\n",
    "df['datetime_norm'] = pd.to_datetime(df['datetime_norm'])\n",
    "\n",
    "# Step 3: Filter out weekends (Saturday and Sunday)\n",
    "df = df[df['datetime_norm'].dt.dayofweek < 5]\n",
    "\n",
    "# Step 4: Reset the index (optional if you want a continuous index after dropping rows)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 5: Save the filtered DataFrame to a new CSV file\n",
    "# df.to_csv('stocks_news_merge.csv', index=False)\n",
    "\n",
    "print(\"Rows corresponding to weekends have been dropped, and the filtered DataFrame is saved to 'stocks_news_merge.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been merged based on dates and stock groups, and the merged DataFrame is saved to 'merged_stocks_data.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/x0bsjzks4917ylvphj74r0fm0000gn/T/ipykernel_2227/3659576724.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['datetime_norm'] = pd.to_datetime(df_sentiment['datetime_norm'])\n",
      "/var/folders/40/x0bsjzks4917ylvphj74r0fm0000gn/T/ipykernel_2227/3659576724.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['datetime_norm'] = df_sentiment['datetime_norm'].dt.date\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load data into DataFrames\n",
    "df_sentiment = df\n",
    "df_hist = pd.read_csv('../stocks_hist.csv')\n",
    "\n",
    "# Step 2: Convert 'datetime_norm' and 'Date' columns to datetime format\n",
    "df_sentiment['datetime_norm'] = pd.to_datetime(df_sentiment['datetime_norm'])\n",
    "df_hist['Date'] = pd.to_datetime(df_hist['Date'])\n",
    "\n",
    "# Step 3: Extract only the date (day, month, year) from the 'datetime_norm' column\n",
    "df_sentiment['datetime_norm'] = df_sentiment['datetime_norm'].dt.date\n",
    "df_hist['Date'] = df_hist['Date'].dt.date\n",
    "\n",
    "# Step 4: Merge the DataFrames based on 'datetime_norm', 'ticker', and 'Date'\n",
    "merged_df = df_sentiment.merge(df_hist, left_on=['datetime_norm', 'related'], right_on=['Date', 'ticker'], how='inner')\n",
    "\n",
    "# Step 5: Drop the duplicate 'Date' and 'ticker' columns\n",
    "merged_df.drop(columns=['Date', 'ticker'], inplace=True)\n",
    "\n",
    "# Step 6: Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('finbert_stocks_input.csv', index=False)\n",
    "\n",
    "print(\"Data has been merged based on dates and stock groups, and the merged DataFrame is saved to 'merged_stocks_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  related    datetime                                           headline  \\\n",
      "0    AAPL  1672719360  Apple downgraded to Neutral from Outperform at...   \n",
      "1    AAPL  1672806957  China's 2025 Strategy Emerges As Top 2023 Inve...   \n",
      "2    AAPL  1672892100  BMW Takes Cues From Apple With Radical Interio...   \n",
      "3    AAPL  1672988286         Covid chaos in China and a new Swiss haven   \n",
      "4    AAPL  1673293335      Apple's VP services Stern to depart - Insider   \n",
      "\n",
      "          id        source                                            summary  \\\n",
      "0  118097919    Thefly.com  Looking for stock market analysis and research...   \n",
      "1  118110299  SeekingAlpha  The most important investment story of 2023 wi...   \n",
      "2  118133082         Yahoo  (Bloomberg) -- BMW AG’s latest prototype could...   \n",
      "3  118167357         Yahoo  This is Kenji from Hong Kong, where the schedu...   \n",
      "4  118194379       Reuters  Apple Inc's vice president of services, Peter ...   \n",
      "\n",
      "                                                 url datetime_norm  \\\n",
      "0  https://finnhub.io/api/news?id=c94bafbd39d76d2...    2023-01-03   \n",
      "1  https://finnhub.io/api/news?id=f6acfb521bd94a6...    2023-01-04   \n",
      "2  https://finnhub.io/api/news?id=60dae185ca4d6d6...    2023-01-05   \n",
      "3  https://finnhub.io/api/news?id=e3cb80be9a64b4f...    2023-01-06   \n",
      "4  https://finnhub.io/api/news?id=576e97b88e07030...    2023-01-09   \n",
      "\n",
      "         Open        High         Low       Close   Adj Close     Volume  \n",
      "0  130.279999  130.899994  124.169998  125.070000  124.706833  112117500  \n",
      "1  126.889999  128.660004  125.080002  126.360001  125.993095   89113600  \n",
      "2  127.129997  127.769997  124.760002  125.019997  124.656982   80962700  \n",
      "3  126.010002  130.289993  124.889999  129.619995  129.243622   87754700  \n",
      "4  130.470001  133.410004  129.889999  130.149994  129.772079   70790800  \n",
      "Merged DataFrame shape: (638, 14)\n",
      "Data types in the 'related' column:\n",
      "object\n",
      "Unique values in the 'related' column:\n",
      "['AAPL' 'AMZN' 'META' 'MSFT' 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_csv('finbert_stocks_input.csv')\n",
    "\n",
    "# Step 2: Print the first few rows of the merged DataFrame\n",
    "print(merged_df.head())\n",
    "\n",
    "# Step 3: Check the shape of the merged DataFrame\n",
    "print(\"Merged DataFrame shape:\", merged_df.shape)\n",
    "\n",
    "# Step 4: Check for any duplicate rows\n",
    "duplicate_rows = merged_df.duplicated()\n",
    "if duplicate_rows.any():\n",
    "    print(\"Warning: Duplicate rows found in the merged DataFrame!\")\n",
    "\n",
    "# Step 5: Perform data validation on specific columns (if applicable)\n",
    "# For example, you can check the data types and unique values in the 'related' column\n",
    "print(\"Data types in the 'related' column:\")\n",
    "print(merged_df['related'].dtype)\n",
    "print(\"Unique values in the 'related' column:\")\n",
    "print(merged_df['related'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
